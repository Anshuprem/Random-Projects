{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m processed_frame, mask \u001b[38;5;241m=\u001b[39m fire_color_mask(frame)  \u001b[38;5;66;03m# Using the correct function name\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Resize HSV reference image\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m hsv_ref_resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhsv_reference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m    122\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFire Detection\u001b[39m\u001b[38;5;124m\"\u001b[39m, processed_frame)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage.feature import local_binary_pattern\n",
    "from scipy.fft import fft\n",
    "\n",
    "# Load the HSV reference image or create a default one if file not found\n",
    "hsv_reference = cv2.imread(\"hsv-0.png\")\n",
    "if hsv_reference is None:\n",
    "    # Create a default HSV reference image\n",
    "    hsv_reference = np.zeros((100, 300, 3), dtype=np.uint8)\n",
    "    # Add some color information for visualization\n",
    "    cv2.putText(hsv_reference, \"HSV Reference\", (50, 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "def fire_color_mask(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # More restrictive HSV range for fire colors\n",
    "    lower_bound1 = np.array([0, 150, 150], dtype=np.uint8)   # Red hues\n",
    "    upper_bound1 = np.array([10, 255, 255], dtype=np.uint8)\n",
    "    lower_bound2 = np.array([170, 150, 150], dtype=np.uint8) # Red hues (wrap-around)\n",
    "    upper_bound2 = np.array([179, 255, 255], dtype=np.uint8)\n",
    "    lower_bound3 = np.array([20, 150, 150], dtype=np.uint8) # Orange-yellow hues\n",
    "    upper_bound3 = np.array([30, 255, 255], dtype=np.uint8)\n",
    "    lower_bound2 = np.array([160, 50, 50], dtype=np.uint8) # Red hues (wrap-around)\n",
    "    upper_bound2 = np.array([179, 255, 255], dtype=np.uint8)\n",
    "    lower_bound3 = np.array([18, 100, 100], dtype=np.uint8) # Orange-yellow hues\n",
    "    upper_bound3 = np.array([35, 255, 255], dtype=np.uint8)\n",
    "    \n",
    "    # Combine masks for red and orange-yellow hues\n",
    "    mask1 = cv2.inRange(hsv, lower_bound1, upper_bound1)\n",
    "    mask2 = cv2.inRange(hsv, lower_bound2, upper_bound2)\n",
    "    mask3 = cv2.inRange(hsv, lower_bound3, upper_bound3)\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    mask = cv2.bitwise_or(mask, mask3)\n",
    "    \n",
    "    # Morphological operations to clean up the mask\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Find contours and filter based on size and shape\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 1000:  # Increased area threshold for better accuracy\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = float(w) / h\n",
    "            if 0.5 < aspect_ratio < 2.0:  # Filter based on aspect ratio to avoid false positives\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"Fire Detected!\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    return frame, mask\n",
    "\n",
    "def detect_motion(frame, background_subtractor):\n",
    "    fg_mask = background_subtractor.apply(frame)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return fg_mask\n",
    "\n",
    "from scipy.fft import fft\n",
    "\n",
    "def check_flicker(intensity_history, sample_rate=30):\n",
    "    if len(intensity_history) < sample_rate:\n",
    "        return False\n",
    "    yf = fft(intensity_history[-sample_rate:])\n",
    "    xf = np.fft.fftfreq(sample_rate, 1/sample_rate)\n",
    "    dominant_freq = np.abs(xf[np.argmax(np.abs(yf))])\n",
    "    return 8 < dominant_freq < 12  # Check for ~10 Hz flicker\n",
    "\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "def analyze_texture(roi_gray):\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(roi_gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp, bins=np.arange(0, n_points + 3), density=True)\n",
    "def process_frame(frame, background_subtractor, intensity_history):\n",
    "    # Fire color detection\n",
    "    _, fire_mask = fire_color_mask(frame)  # Unpack the tuple correctly\n",
    "    \n",
    "    # Motion detection\n",
    "    motion_mask = detect_motion(frame, background_subtractor)\n",
    "    \n",
    "    # Combine fire mask and motion mask\n",
    "    combined_mask = cv2.bitwise_and(fire_mask, motion_mask)\n",
    "    \n",
    "    # Get ROI for further analysis\n",
    "    fire_roi = cv2.bitwise_and(frame, frame, mask=combined_mask)\n",
    "    \n",
    "    # Flicker analysis\n",
    "    gray = cv2.cvtColor(fire_roi, cv2.COLOR_BGR2GRAY)\n",
    "    intensity = np.mean(gray) if np.any(gray) else 0\n",
    "    intensity_history.append(intensity)\n",
    "    is_flickering = check_flicker(intensity_history)\n",
    "    \n",
    "    # Draw detection results\n",
    "    result_frame = frame.copy()\n",
    "    if is_flickering and np.sum(combined_mask) > 5000:\n",
    "        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > 1500:  # Increased threshold\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(result_frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "                cv2.putText(result_frame, \"Fire!\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "    \n",
    "    return result_frame, combined_mask\n",
    "\n",
    "# Main loop\n",
    "cap = cv2.VideoCapture(0)\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=50, varThreshold=16)\n",
    "intensity_history = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Resize HSV reference image if it exists\n",
    "    if hsv_reference is not None:\n",
    "        hsv_ref_resized = cv2.resize(hsv_reference, (300, 100))\n",
    "    else:\n",
    "        hsv_ref_resized = np.zeros((100, 300, 3), dtype=np.uint8)\n",
    "    if not ret:\n",
    "        break\n",
    "    processed_frame, mask = fire_color_mask(frame)  # Using the correct function name\n",
    "    \n",
    "    # Resize HSV reference image\n",
    "    hsv_ref_resized = cv2.resize(hsv_reference, (300, 100))\n",
    "    \n",
    "    # Display results\n",
    "    cv2.imshow(\"Fire Detection\", processed_frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"HSV Reference\", hsv_ref_resized)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# Initialize\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "intensity_history = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # Step 1: Color Masking\n",
    "    fire_roi = fire_color_mask(frame)\n",
    "\n",
    "    # Step 2: Motion Detection\n",
    "    motion_mask = detect_motion(frame, background_subtractor)\n",
    "\n",
    "    # Step 3: Flicker Analysis\n",
    "    gray = cv2.cvtColor(fire_roi, cv2.COLOR_BGR2GRAY)\n",
    "    intensity = np.mean(gray) if np.any(gray) else 0\n",
    "    intensity_history.append(intensity)\n",
    "    is_flickering = check_flicker(intensity_history)\n",
    "\n",
    "    # Step 4: Texture Analysis\n",
    "    texture_feature = analyze_texture(gray)\n",
    "\n",
    "    # Combine Features for Final Decision\n",
    "    if (np.sum(motion_mask) > 1000 and is_flickering and np.sum(fire_roi) > 5000):\n",
    "        print(\"Fire detected!\")\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))\n",
    "\n",
    "def custom_loss(y_pred, y_true, physics_loss_weight=0.1):\n",
    "    bce_loss = nn.BCELoss()(y_pred, y_true)\n",
    "    \n",
    "    # Physics loss: Penalize predictions violating fire flicker/color laws\n",
    "    physics_loss = torch.mean(torch.relu(8 - y_pred_freq) + torch.relu(y_pred_freq - 12))\n",
    "    \n",
    "    return bce_loss + physics_loss_weight * physics_loss\n",
    "\n",
    "model = FireDetector().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = custom_loss\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x.cuda())\n",
    "        loss = criterion(outputs, batch_y.cuda(), physics_loss_weight=0.1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def predict_fire(frame_sequence):\n",
    "    # Preprocess frames (resize, normalize)\n",
    "    frames = [transform(frame) for frame in frame_sequence]\n",
    "    frames = torch.stack(frames).unsqueeze(0).cuda()  # Add batch dim\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prob = model(frames).item()\n",
    "    \n",
    "    return prob > 0.5  # Fire if probability > 50%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch-cam (from versions: none)\n",
      "ERROR: No matching distribution found for torch-cam\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchcam'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms, models\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchcam\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradCAM  \u001b[38;5;66;03m# For explainability\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 1. INITIALIZATION\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[0;32m     15\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchcam'"
     ]
    }
   ],
   "source": [
    "%pip install torch-cam\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from skimage.feature import local_binary_pattern\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torchcam.methods import GradCAM  # For explainability\n",
    "\n",
    "# ----------------------\n",
    "# 1. INITIALIZATION\n",
    "# ----------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "intensity_history = []\n",
    "\n",
    "# Load HSV reference image\n",
    "hsv_reference = cv2.imread(\"hsv-0.png\") or np.zeros((100, 300, 3), dtype=np.uint8)\n",
    "\n",
    "# ----------------------\n",
    "# 2. FIRE DETECTION FUNCTIONS\n",
    "# ----------------------\n",
    "def fire_color_mask(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Adjusted HSV range for fire-like colors (red, orange, yellow)\n",
    "    lower_bound1 = np.array([0, 50, 50], dtype=np.uint8)   # Red hues\n",
    "    upper_bound1 = np.array([10, 255, 255], dtype=np.uint8)\n",
    "    lower_bound2 = np.array([160, 50, 50], dtype=np.uint8) # Red hues (wrap-around)\n",
    "    upper_bound2 = np.array([179, 255, 255], dtype=np.uint8)\n",
    "    lower_bound3 = np.array([18, 100, 100], dtype=np.uint8) # Orange-yellow hues\n",
    "    upper_bound3 = np.array([35, 255, 255], dtype=np.uint8)\n",
    "    \n",
    "    # Combine masks for red and orange-yellow hues\n",
    "    mask1 = cv2.inRange(hsv, lower_bound1, upper_bound1)\n",
    "    mask2 = cv2.inRange(hsv, lower_bound2, upper_bound2)\n",
    "    mask3 = cv2.inRange(hsv, lower_bound3, upper_bound3)\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    mask = cv2.bitwise_or(mask, mask3)\n",
    "    \n",
    "    # Morphological operations to clean up the mask\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Find contours and filter based on size and shape\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 1000:  # Increased area threshold for better accuracy\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = float(w) / h\n",
    "            if 0.5 < aspect_ratio < 2.0:  # Filter based on aspect ratio to avoid false positives\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"Fire Detected!\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    return frame, mask\n",
    "\n",
    "    mask = cv2.bitwise_or(\n",
    "        cv2.inRange(hsv, lower1, upper1),\n",
    "        cv2.inRange(hsv, lower2, upper2)\n",
    "    )\n",
    "    mask = cv2.bitwise_or(mask, cv2.inRange(hsv, lower3, upper3))\n",
    "    \n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "def detect_motion(frame):\n",
    "    fg_mask = background_subtractor.apply(frame)\n",
    "    return cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))\n",
    "\n",
    "def check_flicker(history, sample_rate=30):\n",
    "    if len(history) < sample_rate: return False\n",
    "    yf = fft(history[-sample_rate:])\n",
    "    dominant_freq = np.abs(np.fft.fftfreq(sample_rate, 1/sample_rate)[np.argmax(np.abs(yf))])\n",
    "    return 8 < dominant_freq < 12  # Fire flickers at ~10Hz\n",
    "\n",
    "def analyze_texture(roi_gray):\n",
    "    lbp = local_binary_pattern(roi_gray, 24, 3, method='uniform')\n",
    "    return np.histogram(lbp, bins=np.arange(27), density=True)[0]\n",
    "\n",
    "# ----------------------\n",
    "# 3. DEEP LEARNING MODEL\n",
    "# ----------------------\n",
    "class FireDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Identity()\n",
    "        self.lstm = nn.LSTM(512, 128, batch_first=True)\n",
    "        self.classifier = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "        features = self.cnn(x.view(-1, *x.shape[2:]))\n",
    "        _, (hidden, _) = self.lstm(features.view(batch_size, seq_len, -1))\n",
    "        return torch.sigmoid(self.classifier(hidden[-1]))\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FireDetector().to(device)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# 4. MAIN PROCESSING LOOP\n",
    "# ----------------------\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    # Traditional Computer Vision\n",
    "    mask = fire_color_mask(frame)\n",
    "    motion_mask = detect_motion(frame)\n",
    "    gray = cv2.cvtColor(cv2.bitwise_and(frame, frame, mask=mask), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Feature Extraction\n",
    "    intensity_history.append(np.mean(gray) if np.any(gray) else 0)\n",
    "    is_flickering = check_flicker(intensity_history)\n",
    "    texture_feat = analyze_texture(gray)\n",
    "    \n",
    "    # Deep Learning\n",
    "    frame_buffer.append(transform(frame))\n",
    "    if len(frame_buffer) == 30:  # Process every 1 sec (30fps)\n",
    "        with torch.no_grad():\n",
    "            prob = model(torch.stack(frame_buffer).unsqueeze(0).to(device)).item()\n",
    "        frame_buffer = []\n",
    "    \n",
    "    # Decision Fusion\n",
    "    cv_decision = (np.sum(motion_mask) > 1000 and is_flickering and np.sum(mask) > 5000)\n",
    "    dl_decision = prob > 0.7 if len(frame_buffer)==0 else False\n",
    "    \n",
    "    if cv_decision or dl_decision:\n",
    "        x,y,w,h = cv2.boundingRect(cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0][0])\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 2)\n",
    "        cv2.putText(frame, \"FIRE DETECTED\", (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    cv2.imshow(\"Fire Mask\", mask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
